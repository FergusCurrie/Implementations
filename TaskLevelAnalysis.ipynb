{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleveland', 'ionosphere', 'ecoli', 'iris', 'mammo_graphic', 'wisconsin_breast_cancer', 'australia', 'postop', 'yeast', 'spec']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import sys \n",
    "from code.data_processing import get_all_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ResultHandling import ResultHandling\n",
    "print(get_all_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard method for composing result handlilngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleveland']\n",
      "['cleveland']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if 1:\n",
    "    job = 'bagboost'\n",
    "    experiment_name = 'bagboost_experiment'\n",
    "    RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    for train in [True, False]:\n",
    "        skipped_datasets = []\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in RH.model_names:\n",
    "                plots.append(RH.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            RH.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=RH.model_names)\n",
    "        print(skipped_datasets)\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving fast bag vs baseline gp vs basline bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mammo_graphic']\n",
      "['mammo_graphic']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if 1:\n",
    "    job = 'fastbag_ham'\n",
    "    experiment_name = 'fastbag'\n",
    "    RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    other = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    for train in [True, False]:\n",
    "        skipped_datasets = []\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in other.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(other.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "            for model_nam in RH.model_names:\n",
    "                plots.append(RH.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                if model_nam == 'fastbaggp':\n",
    "                    model_nam = 'rfbag'\n",
    "                if model_nam == 'ham_fastbaggp':\n",
    "                    model_nam = 'hrfbag'\n",
    "                plot_labels.append(model_nam)\n",
    "            RH.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['gp', 'baggp', 'rfbag', 'rfham'])\n",
    "        print(skipped_datasets)\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'pca'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    pca = ResultHandling('pca', 'dr', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        \n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "\n",
    "            for i in range(4):\n",
    "                j = i + 1\n",
    "                plots.append(pca.get_cond_data(mgen=False, train=train, model_name='pcabag', dataset_name=f'{ds}_{j}',col='full_acc'))\n",
    "                plot_labels.append(f'pca_{j}')\n",
    "            pca.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            \n",
    "            # \n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "\n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['gp', 'baggp', 'pca1', 'pca2', 'pca3', 'pca4'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis bag m3gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'm3gpbag'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    m3gpbag = ResultHandling('m3gpbag', 'm3gp_bag', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        \n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "            for model_nam in m3gpbag.model_names:\n",
    "                plots.append(m3gpbag.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            m3gpbag.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['GP', 'BagModel', 'm3gp'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis bag MOGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'bagmogp'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    mogpbag = ResultHandling('bagmogp', 'bagmogp', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    mogp500 = ResultHandling('mogp500', 'bagmogp', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            plot_labels, plots = [], []\n",
    "\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "\n",
    "            for model_nam in mogpbag.model_names:\n",
    "                plots.append(mogpbag.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "\n",
    "            for model_nam in mogp500.model_names:\n",
    "                plots.append(mogp500.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            mogpbag.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "        \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['GP', 'BagModel', 'mogp250', 'mogp500'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for generating table and wilson cox test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &        GP &     baggp &    nichgp &      ccgp \\\\\n",
      "\\midrule\n",
      "cleveland               &  0.883414 &  0.840419 &       NaN &  0.922383 \\\\\n",
      "ionosphere              &  0.944082 &  0.905034 &  0.953061 &  0.988707 \\\\\n",
      "ecoli                   &  0.779858 &  0.518723 &  0.737872 &  0.766241 \\\\\n",
      "iris                    &  0.984762 &  0.983810 &  0.983492 &  0.974921 \\\\\n",
      "mammo\\_graphic           &  0.847619 &  0.819966 &  0.844865 &  0.860700 \\\\\n",
      "wisconsin\\_breast\\_cancer &  0.982078 &  0.955439 &  0.974407 &  0.984868 \\\\\n",
      "australia               &  0.897930 &  0.854727 &  0.887371 &  0.928640 \\\\\n",
      "postop                  &  0.872131 &  0.879235 &  0.868306 &  0.915847 \\\\\n",
      "yeast                   &  0.425209 &  0.322929 &  0.404303 &  0.443256 \\\\\n",
      "spec                    &  0.826523 &  0.782079 &  0.826523 &  0.896953 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = RH.get_model_vs_dataset_dataframe(training=True)\n",
    "print(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &        GP &     baggp &    nichgp &      ccgp \\\\\n",
      "\\midrule\n",
      "cleveland               &  0.791852 &  0.776667 &       NaN &  0.779630 \\\\\n",
      "ionosphere              &  0.866038 &  0.821384 &  0.896855 &  0.897484 \\\\\n",
      "ecoli                   &  0.734653 &  0.501320 &  0.705611 &  0.703960 \\\\\n",
      "iris                    &  0.947407 &  0.953333 &  0.950370 &  0.928889 \\\\\n",
      "mammo\\_graphic           &  0.821553 &  0.802276 &  0.829050 &  0.825837 \\\\\n",
      "wisconsin\\_breast\\_cancer &  0.961138 &  0.940325 &  0.957886 &  0.959837 \\\\\n",
      "australia               &  0.851369 &  0.825765 &  0.851852 &  0.848953 \\\\\n",
      "postop                  &  0.628395 &  0.590123 &  0.628395 &  0.597531 \\\\\n",
      "yeast                   &  0.401495 &  0.311734 &  0.392601 &  0.413303 \\\\\n",
      "spec                    &  0.683128 &  0.649794 &  0.702469 &  0.688477 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = RH.get_model_vs_dataset_dataframe(training=False)\n",
    "print(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baggp', 'GP', RanksumsResult(statistic=-3.1096223731159465, pvalue=0.0009366333448071793)]\n",
      "['nichgp', 'GP', RanksumsResult(statistic=0.5317782348576343, pvalue=0.7025602005035679)]\n",
      "['nichgp', 'baggp', RanksumsResult(statistic=3.3804082908359097, pvalue=0.9996381088767804)]\n",
      "['ccgp', 'GP', RanksumsResult(statistic=-0.050633808710991254, pvalue=0.4798086609564054)]\n",
      "['ccgp', 'baggp', RanksumsResult(statistic=2.946887666979691, pvalue=0.9983950510652889)]\n",
      "['ccgp', 'nichgp', RanksumsResult(statistic=-0.6181157931031984, pvalue=0.2682495062229687)]\n"
     ]
    }
   ],
   "source": [
    "RH.wilcoxon_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "q = np.array([1,2,3])\n",
    "print(np.mean(q))\n",
    "print(type(float(np.mean(q))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GP', 'baggp', 'nichgp', 'ccgp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RH.model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# For a given experiment we use training and test per experiment \n",
    "\n",
    "RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "f = RH.get_model_vs_dataset_dataframe(training=False)\n",
    "print(type(f.to_latex()))\n",
    "with open('sometexfile.tex','w') as file:\n",
    "    file.write(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &         0 &         1 &         2 &         3 \\\\\n",
      "\\midrule\n",
      "0  &  0.617284 &  0.641975 &  0.592593 &  0.728395 \\\\\n",
      "1  &  0.728395 &  0.666667 &  0.654321 &  0.654321 \\\\\n",
      "2  &  0.666667 &  0.703704 &  0.679012 &  0.753086 \\\\\n",
      "3  &  0.641975 &  0.604938 &  0.666667 &  0.629630 \\\\\n",
      "4  &  0.592593 &  0.580247 &  0.604938 &  0.666667 \\\\\n",
      "5  &  0.641975 &  0.629630 &  0.666667 &  0.679012 \\\\\n",
      "6  &  0.679012 &  0.703704 &  0.629630 &  0.716049 \\\\\n",
      "7  &  0.629630 &  0.567901 &  0.728395 &  0.641975 \\\\\n",
      "8  &  0.777778 &  0.703704 &  0.604938 &  0.740741 \\\\\n",
      "9  &  0.641975 &  0.654321 &  0.716049 &  0.703704 \\\\\n",
      "10 &  0.691358 &  0.654321 &  0.740741 &  0.777778 \\\\\n",
      "11 &  0.790123 &  0.654321 &  0.604938 &  0.654321 \\\\\n",
      "12 &  0.765432 &  0.777778 &  0.802469 &  0.765432 \\\\\n",
      "13 &  0.604938 &  0.679012 &  0.679012 &  0.679012 \\\\\n",
      "14 &  0.679012 &  0.629630 &  0.703704 &  0.740741 \\\\\n",
      "15 &  0.679012 &  0.641975 &  0.703704 &  0.691358 \\\\\n",
      "16 &  0.654321 &  0.617284 &  0.679012 &  0.740741 \\\\\n",
      "17 &  0.679012 &  0.641975 &  0.691358 &  0.617284 \\\\\n",
      "18 &  0.679012 &  0.691358 &  0.493827 &  0.716049 \\\\\n",
      "19 &  0.716049 &  0.740741 &  0.629630 &  0.604938 \\\\\n",
      "20 &  0.679012 &  0.518519 &  0.641975 &  0.641975 \\\\\n",
      "21 &  0.666667 &  0.592593 &  0.654321 &  0.641975 \\\\\n",
      "22 &  0.666667 &  0.703704 &  0.604938 &  0.716049 \\\\\n",
      "23 &  0.765432 &  0.679012 &  0.753086 &  0.666667 \\\\\n",
      "24 &  0.703704 &  0.679012 &  0.654321 &  0.641975 \\\\\n",
      "25 &  0.716049 &  0.641975 &  0.629630 &  0.728395 \\\\\n",
      "26 &  0.654321 &  0.592593 &  0.641975 &  0.716049 \\\\\n",
      "27 &  0.629630 &  0.543210 &  0.654321 &  0.716049 \\\\\n",
      "28 &  0.740741 &  0.691358 &  0.802469 &  0.691358 \\\\\n",
      "29 &  0.716049 &  0.666667 &  0.654321 &  0.703704 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data=np.array(plots).transpose()).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
