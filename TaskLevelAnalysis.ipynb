{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleveland', 'ionosphere', 'ecoli', 'iris', 'mammo_graphic', 'wisconsin_breast_cancer', 'australia', 'postop', 'yeast', 'spec']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import sys \n",
    "from code.data_processing import get_all_datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ResultHandling import ResultHandling\n",
    "print(get_all_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard method for composing result handlilngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(directory):\n",
    "    file = open(directory) #'results_finished/bagboost/1/4083559_1_info.txt')\n",
    "    line = [l for l in file][0].split('{')\n",
    "    line[-1] = line[-1].replace('}', '')\n",
    "    line = line[1].split(',')\n",
    "\n",
    "    f = {}\n",
    "    for x in line:\n",
    "        x = x.split(':')\n",
    "        key = x[0].replace(\"'\",'').strip()\n",
    "        f[key] = str(x[1]).strip()\n",
    "        \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<model.Model object at 0x12fa4dd60>, <model.Model object at 0x12fa4ddc0>]\n",
      "[{'p_size': 500, 'max_depth': 8, 'pc': 0.6, 'pm': 0.4, 'ngen': 50, 'verbose': False}]\n",
      "[{'p_size': 250, 'max_depth': 8, 'pc': 0.6, 'pm': 0.4, 'ngen': 50, 'verbose': False}]\n"
     ]
    }
   ],
   "source": [
    "from experiments.get_experiment import get_experiment\n",
    "exp = get_experiment('bagmogp')\n",
    "print(exp['models'])\n",
    "\n",
    "params_stack = {}\n",
    "for model in exp['models']:\n",
    "    model.model_name\n",
    "    print(model.params)\n",
    "    df = model.params[0]\n",
    "    params_stack = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 1:\n",
    "    job = 'bagboost'\n",
    "    experiment_name = 'bagboost_experiment'\n",
    "    RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        skipped_datasets = []\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in RH.model_names:\n",
    "                plots.append(RH.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            RH.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=RH.model_names)\n",
    "        print(skipped_datasets)\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving fast bag vs baseline gp vs basline bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 1:\n",
    "    job = 'fastbag_ham'\n",
    "    experiment_name = 'fastbag'\n",
    "    RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    other = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    for train in [True, False]:\n",
    "        skipped_datasets = []\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in other.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(other.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "            for model_nam in RH.model_names:\n",
    "                plots.append(RH.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                if model_nam == 'fastbaggp':\n",
    "                    model_nam = 'rfbag'\n",
    "                if model_nam == 'ham_fastbaggp':\n",
    "                    model_nam = 'hrfbag'\n",
    "                plot_labels.append(model_nam)\n",
    "            RH.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['gp', 'baggp', 'rfbag', 'rfham'])\n",
    "        print(skipped_datasets)\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'pca'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    pca = ResultHandling('pca', 'dr', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        \n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "\n",
    "            for i in range(4):\n",
    "                j = i + 1\n",
    "                plots.append(pca.get_cond_data(mgen=False, train=train, model_name='pcabag', dataset_name=f'{ds}_{j}',col='full_acc'))\n",
    "                plot_labels.append(f'pca_{j}')\n",
    "            pca.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            \n",
    "            # \n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "\n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['gp', 'baggp', 'pca1', 'pca2', 'pca3', 'pca4'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis bag m3gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'm3gpbag'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    m3gpbag = ResultHandling('m3gpbag', 'm3gp_bag', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        \n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            # Per model train\n",
    "            plot_labels, plots = [], []\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "            for model_nam in m3gpbag.model_names:\n",
    "                plots.append(m3gpbag.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            m3gpbag.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "                \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['GP', 'BagModel', 'm3gp'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis bag MOGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    job = 'bagmogp'\n",
    "    base = ResultHandling('bagboost', 'bagboost_experiment', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    mogpbag = ResultHandling('bagmogp', 'bagmogp', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    mogp500 = ResultHandling('mogp500', 'bagmogp', height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "    \n",
    "    for train in [True, False]:\n",
    "        latex_data = [] # at the end hsould be (ndatasets, nmodels, nseeds)\n",
    "        training_string = 'train' if train else 'test'\n",
    "        skipped_datasets = []\n",
    "        \n",
    "        for ds in get_all_datasets():\n",
    "            plot_labels, plots = [], []\n",
    "\n",
    "            for model_nam in base.model_names:\n",
    "                if model_nam in ['GP', 'baggp']:\n",
    "                    plots.append(base.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                    plot_labels.append(model_nam)\n",
    "\n",
    "            for model_nam in mogpbag.model_names:\n",
    "                plots.append(mogpbag.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "\n",
    "            for model_nam in mogp500.model_names:\n",
    "                plots.append(mogp500.get_cond_data(mgen=False, train=train, model_name=model_nam, dataset_name=ds,col='full_acc'))\n",
    "                plot_labels.append(model_nam)\n",
    "            mogpbag.box_plot(boxes=plots, labels=plot_labels, save=True, draw=False, figname=f'{job}_{ds}_{training_string}')\n",
    "\n",
    "            if len(np.array(plots).shape) == 2:\n",
    "                latex_data.append(np.array(plots))\n",
    "            else:\n",
    "                skipped_datasets.append(ds)\n",
    "        \n",
    "        # Create table \n",
    "        np_latex_data = np.array(latex_data)\n",
    "        np_latex_data = np.mean(np_latex_data, axis=2)\n",
    "        df = pd.DataFrame(data=np_latex_data, columns=['GP', 'BagModel', 'mogp250', 'mogp500'])\n",
    "        df.index = [ds for ds in get_all_datasets() if ds not in skipped_datasets]\n",
    "        with open(f'tables/{job}_{training_string}.tex','w') as file:\n",
    "            file.write(df.to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for generating table and wilson cox test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RH.get_model_vs_dataset_dataframe(training=True)\n",
    "print(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RH.get_model_vs_dataset_dataframe(training=False)\n",
    "print(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH.wilcoxon_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([1,2,3])\n",
    "print(np.mean(q))\n",
    "print(type(float(np.mean(q))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH.model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given experiment we use training and test per experiment \n",
    "\n",
    "RH = ResultHandling(job, experiment_name, height=10, width = 10, box_label_size=30, target_dir='results_finished')\n",
    "f = RH.get_model_vs_dataset_dataframe(training=False)\n",
    "print(type(f.to_latex()))\n",
    "with open('sometexfile.tex','w') as file:\n",
    "    file.write(f.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(data=np.array(plots).transpose()).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
